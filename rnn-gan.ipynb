{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#input_file = 'mariel-1.npy'\n",
    "input_file = 'carrie-10-mins.npy'\n",
    "\n",
    "X0 = np.load(os.path.join(\"data/npy\", input_file))\n",
    "\n",
    "if input_file == 'mariel-1.npy':\n",
    "    X0 = X0.transpose((1,0,2))\n",
    "    X0 = X0[1300:7000]\n",
    "    X0[:,:,2] *= -1\n",
    "    X = X0.copy()\n",
    "    X -= X.mean(axis=(0,1))\n",
    "    X *= 0.5\n",
    "elif input_file == 'carrie-10-min-scaled.npy':\n",
    "    X0 = X0.transpose((1,0,2))\n",
    "    X = X0.copy()\n",
    "    X[:,:,1] = X0[:,:,2]\n",
    "    X[:,:,2] = X0[:,:,1]\n",
    "    X = X[100:]\n",
    "    X[:,:,:2] -= 0.5\n",
    "if input_file == 'carrie-10-mins.npy':\n",
    "    X0 = X0.transpose((1,0,2))\n",
    "    X0 = X0[100:]\n",
    "    X0[:,:,2] *= -1\n",
    "    X = X0.copy()\n",
    "    X -= X.mean(axis=(0,1))\n",
    "    X *= 0.25\n",
    "    \n",
    "    \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X.mean(axis=1));\n",
    "plt.figure()\n",
    "plt.hist([X[:,:,0].flatten(),X[:,:,1].flatten(),X[:,:,2].flatten()], histtype='step');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.max(axis=(0,1)))\n",
    "print(X.min(axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.mean(axis=(0,1)))\n",
    "print(X.std(axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "from mpl_toolkits.mplot3d.art3d import juggle_axes\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# ask matplotlib to plot up to 2^128 frames in animations\n",
    "matplotlib.rcParams['animation.embed_limit'] = 2**128\n",
    "\n",
    "def update_points(time, points, df):\n",
    "  '''\n",
    "  Callback function called by plotting function below. Mutates the vertex\n",
    "  positions of each value in `points` so the animation moves\n",
    "  @param int time: the index of the time slice to visualize within `df`\n",
    "  @param mpl_toolkits.mplot3d.art3d.Path3DCollection points: the actual\n",
    "    geometry collection whose internal values this function mutates to move\n",
    "    the displayed points\n",
    "  @param numpy.ndarray df: a numpy array with the following three axes:\n",
    "    df.shape[0] = n_vertices\n",
    "    df.shape[1] = n_time_slices\n",
    "    df.shape[2] = n_dimensions\n",
    "  '''\n",
    "  points._offsets3d = juggle_axes(df[time,:,0], df[time,:,1], df[time,:,2], 'z')\n",
    "\n",
    "def animate(seq, frames=None, axis_min=-.5, axis_max=0.5, speed=45):\n",
    "    if frames is None:\n",
    "        frames = len(seq)\n",
    "    fig = plt.figure()\n",
    "    ax = p3.Axes3D(fig)\n",
    "    ax.set_xlim(axis_min, axis_max)\n",
    "    ax.set_ylim(axis_min, axis_max)\n",
    "    ax.set_zlim(axis_min, axis_max*1.5)\n",
    "    points = ax.scatter(seq[0,:,0], seq[0,:,1], seq[0,:,2], depthshade=False)\n",
    "    return animation.FuncAnimation(\n",
    "        fig,\n",
    "        update_points,\n",
    "        frames,\n",
    "        interval=speed,\n",
    "        fargs=(points, seq),\n",
    "        blit=False,\n",
    "    ).to_jshtml()\n",
    "\n",
    "def plot_pose(x):\n",
    "    fig = plt.figure()\n",
    "    ax = p3.Axes3D(fig)\n",
    "    ax.set_xlim(-0.5,0.5)\n",
    "    ax.set_ylim(-0.5,0.5)\n",
    "    ax.set_zlim(-0.5,0.5*1.5)\n",
    "    ax.scatter(x[:,0], x[:,1], x[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(animate(X[100:300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "# config for Gatsby cores\n",
    "if 'gatsby' in os.environ['HOSTNAME']:\n",
    "\n",
    "    # specify target gpu device\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0' # either '0' or '1' to utilize Titan X GPUs\n",
    "\n",
    "    # allow dynamic GPU allocation\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = tf.Session(config=config)\n",
    "    \n",
    "import keras.backend as K\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_model(lookback=60, npred=4, n_cells=(32,32,32), n_cells_disc=(32,32,), noise_dim=128):\n",
    "    K.clear_session()\n",
    "    \n",
    "    input_seq = layers.Input((lookback, X.shape[1], X.shape[2]))\n",
    "    H = input_seq\n",
    "    \n",
    "    input_noise = layers.Input((noise_dim,))\n",
    "    \n",
    "    H = layers.Reshape((lookback, X.shape[1]*X.shape[2]))(H)\n",
    "    for nc in n_cells[:-1]:\n",
    "        H = layers.CuDNNLSTM(nc, return_sequences=True)(H)\n",
    "    H = layers.CuDNNLSTM(n_cells[-1])(H)\n",
    "    H = layers.Concatenate()([H, input_noise])\n",
    "    H = layers.Dense(npred*X.shape[1]*X.shape[2], activation='tanh')(H)\n",
    "    H = layers.Reshape((npred,X.shape[1],X.shape[2]))(H)\n",
    "    output_seq = H\n",
    "    \n",
    "    generator = Model([input_seq, input_noise], output_seq)\n",
    "    #generator.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    disc_input1 = layers.Input((lookback, X.shape[1], X.shape[2]))\n",
    "    disc_input2 = layers.Input((npred, X.shape[1], X.shape[2]))\n",
    "    \n",
    "    H1 = layers.Reshape((lookback, X.shape[1]*X.shape[2]))(disc_input1)\n",
    "    H2 = layers.Reshape((npred, X.shape[1]*X.shape[2]))(disc_input2)\n",
    "    #H = H2\n",
    "    H = layers.Concatenate(axis=1)([H1,H2])\n",
    "    #H = layers.Reshape((lookback+npred, X.shape[1]*X.shape[2]))(H)\n",
    "    #H = layers.Reshape((npred, X.shape[1]*X.shape[2]))(H)\n",
    "    \n",
    "    for nc in n_cells_disc[:-1]:\n",
    "        H = layers.CuDNNLSTM(nc, return_sequences=True)(H)\n",
    "    H = layers.CuDNNLSTM(n_cells_disc[-1])(H)\n",
    "    #H = layers.BatchNormalization()(H)\n",
    "    H = layers.Dense(32, activation='sigmoid')(H)\n",
    "    HH = layers.Dense(32, activation='sigmoid')(H2)\n",
    "    HH = layers.Flatten()(HH)\n",
    "    H = layers.Concatenate()([H,HH])\n",
    "    #H = layers.BatchNormalization()(H)\n",
    "    H = layers.Dense(2, activation='softmax')(H)\n",
    "    disc_output = H\n",
    "    \n",
    "    discriminator = Model([disc_input1,disc_input2], disc_output)\n",
    "    #discriminator = Model(disc_input2, disc_output)\n",
    "    discriminator.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    full_output = discriminator([input_seq,generator([input_seq, input_noise])])\n",
    "    full = Model([input_seq, input_noise], full_output)\n",
    "    full.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    discriminator.trainable = True\n",
    "    \n",
    "    return generator, discriminator, full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 16\n",
    "npred = 4\n",
    "noise_dim = 128\n",
    "\n",
    "gen, disc, full = mk_model(lookback=lookback, npred=npred, noise_dim=noise_dim)\n",
    "disc.summary()\n",
    "disc.trainable = False\n",
    "full.summary()\n",
    "disc.trainable = True\n",
    "\n",
    "d_losses = []\n",
    "g_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(full.optimizer.lr, 1e-4)\n",
    "K.set_value(disc.optimizer.lr, 3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 256\n",
    "do_rotation = True\n",
    "\n",
    "nbatches = (len(X)-batch_size*lookback-npred)//batch_size\n",
    "\n",
    "y_real = to_categorical(np.ones(batch_size),2)\n",
    "y_fake = to_categorical(np.zeros(batch_size),2)\n",
    "#y_gan = to_categorical(np.ones(2*batch_size),2)\n",
    "print(\"Nbatches =\", nbatches)\n",
    "for iepoch in range(epochs):\n",
    "    offsets = np.random.choice(len(X)-batch_size*lookback-npred, replace=False, size=(nbatches,batch_size))\n",
    "    \n",
    "    d_loss = 0\n",
    "    g_loss = 0\n",
    "    for ibatch in range(nbatches):\n",
    "        batch_idxs = offsets[ibatch].repeat(lookback).reshape(batch_size,lookback) + np.arange(lookback)\n",
    "        truth_idxs = offsets[ibatch].repeat(npred).reshape(batch_size,npred) + np.arange(npred) + lookback\n",
    "        \n",
    "        if do_rotation:\n",
    "            theta = 2*np.pi*np.random.rand()\n",
    "            c,s = np.cos(theta), np.sin(theta)\n",
    "            rot = np.array([[c,-s,0],[s,c,0],[0,0,1]])\n",
    "            x1_real = rot.dot(X[batch_idxs].transpose((0,1,3,2))).transpose((1,2,3,0))\n",
    "            x2_real = rot.dot(X[truth_idxs].transpose((0,1,3,2))).transpose((1,2,3,0))\n",
    "        else:\n",
    "            x1_real = X[batch_idxs]\n",
    "            x2_real = X[truth_idxs]\n",
    "        \n",
    "        noise = np.random.normal(size=(batch_size,noise_dim))\n",
    "        x2_fake = gen.predict([x1_real, noise])\n",
    "        \n",
    "        disc.trainable = True\n",
    "        l, a = disc.train_on_batch([x1_real, x2_real], y_real)\n",
    "        d_loss += 0.5*l\n",
    "        l,a = disc.train_on_batch([x1_real, x2_fake], y_fake)\n",
    "        d_loss += 0.5*l\n",
    "        \n",
    "        if do_rotation:\n",
    "            theta = 2*np.pi*np.random.rand()\n",
    "            c,s = np.cos(theta), np.sin(theta)\n",
    "            rot = np.array([[c,-s,0],[s,c,0],[0,0,1]])\n",
    "            x1_real = rot.dot(X[batch_idxs].transpose((0,1,3,2))).transpose((1,2,3,0))\n",
    "        \n",
    "        disc.trainable = False\n",
    "        noise = np.random.normal(size=(batch_size,noise_dim))\n",
    "        g_loss += full.train_on_batch([x1_real, noise], y_real)\n",
    "        \n",
    "    d_losses.append(d_loss/nbatches)\n",
    "    g_losses.append(g_loss/nbatches)\n",
    "    print(\"Epoch %d/%d: L(d)=%.2e L(g)=%.2e\" % (iepoch, epochs, d_losses[-1], g_losses[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_losses, label='disc')\n",
    "plt.plot(g_losses, label='gen')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iprompt = np.random.randint(len(X)-batch_size*lookback-1)\n",
    "ngen = 2*lookback\n",
    "\n",
    "gen_seq = np.zeros((lookback+ngen, X.shape[1], X.shape[2]))\n",
    "gen_seq[:lookback] = X[iprompt:iprompt+lookback]\n",
    "\n",
    "for i in range(ngen):\n",
    "    next_frame = gen.predict([np.expand_dims(gen_seq[i:i+lookback],0),np.random.normal(size=(1,noise_dim))])[0,0]\n",
    "    gen_seq[i+lookback] = next_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first generated frame\n",
    "plot_pose(gen_seq[lookback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(animate(gen_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
